场景 4：端到端研究工作流
==========================================

完整研究工作流的高级管道，从数据加载到分析和可视化，
无需详细了解模型实现。

教程
---------

.. toctree::
   :maxdepth: 1
   :caption: Research Pipelines

   01_theta_sweep_pipeline

概览
--------

此场景演示了使用预构建管道的常见研究任务的简化工作流。
非常适合实验神经科学家和想要快速分析数据而不深入
实现细节的研究人员。

** 教程 1：Theta 扫描管道 **

- 一行代码完成完整的 theta 扫描分析
- 从各种来源加载轨迹数据
- 自动仿真和可视化
- 为高级用户提供可自定义的参数
- 批量处理多个数据集

谁应该使用管道？
--------------------------

** 完美适合：**

- 没有深厚编码专业知识的实验神经科学家
- 快速原型设计和探索性分析
- 多个数据集的标准化处理
- 出版质量的图表生成
- 教学和演示

** 在以下情况考虑手动方法：**

- 实现非标准模型架构
- 开发新的分析方法
- 需要对每一步进行细粒度控制
- 扩展管道功能

学习路径
-------------

** 快速开始：**

1. 准备你的轨迹数据（位置 + 时间戳）
2. 使用默认参数运行管道
3. 检查生成的图表和动画
4. 根据需要自定义参数

** 高级用法：**

- 仿真数据的自定义后处理
- 批量处理多个会话
- 参数扫描和优化
- 与现有分析工作流集成

先决条件
-------------

- 基本的 Python 知识
- 理解你的实验数据格式
- 轨迹数据（随时间变化的位置）

预计时间
--------------

- 教程 1：约 30-35 分钟
- 为你自己的数据进行设置：约 15-30 分钟
- 总计：约 60 分钟

管道功能
-----------------

ThetaSweepPipeline 提供：

- ** 自动数据验证 ** - 检查数据格式和质量
- ** 网络仿真 ** - 方向细胞和网格细胞
- **Theta 调制 ** - 速度依赖的振荡
- ** 可视化套件 ** - 轨迹图、种群活动、动画
- ** 原始数据导出 ** - 用于自定义分析
- ** 灵活的配置 ** - 从简单到高级用法

数据输入格式
------------------

轨迹数据支持的格式：

- CSV 文件
- NumPy 数组（`.npy`）
- MATLAB 文件（`.mat`）
- Pandas DataFrames
- DeepLabCut 输出
- Bonsai 跟踪输出
- 自定义格式（带预处理）

后续步骤
----------

完成本场景后：

- 将管道应用于你自己的实验数据
- 使用原始仿真输出探索自定义分析
- 在场景 1 中学习实现细节以进行自定义
- 为库贡献新的管道