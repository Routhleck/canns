{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Concepts of Continuous Attractor Neural Networks\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/routhleck/canns/HEAD?filepath=docs%2Fen%2Fnotebooks%2F03_core_concepts.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/routhleck/canns/blob/master/docs/en/notebooks/03_core_concepts.ipynb)\n",
    "\n",
    "This notebook provides a comprehensive introduction to the mathematical foundations and key concepts underlying Continuous Attractor Neural Networks (CANNs). Understanding these concepts is crucial for effectively using the CANNs library and designing your own experiments.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Mathematical Foundation](#Mathematical-Foundation)\n",
    "2. [Network Dynamics](#Network-Dynamics)\n",
    "3. [Connectivity Patterns](#Connectivity-Patterns)\n",
    "4. [Attractor Dynamics](#Attractor-Dynamics)\n",
    "5. [Population Coding](#Population-Coding)\n",
    "6. [Slow Feature Analysis (SFA)](#Slow-Feature-Analysis)\n",
    "7. [Hierarchical Networks](#Hierarchical-Networks)\n",
    "8. [Practical Implications](#Practical-Implications)\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Basic Network Equation\n",
    "\n",
    "The dynamics of a CANN are governed by the following differential equation:\n",
    "\n",
    "$$\\tau \\frac{du_i}{dt} = -u_i + \\sum_j W_{ij} r_j + I_i^{ext}$$\n",
    "\n",
    "Where:\n",
    "- $u_i$: Membrane potential of neuron $i$\n",
    "- $\\tau$: Time constant\n",
    "- $W_{ij}$: Connection weight from neuron $j$ to neuron $i$\n",
    "- $r_j$: Firing rate of neuron $j$\n",
    "- $I_i^{ext}$: External input to neuron $i$\n",
    "\n",
    "Let's implement and visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import brainstate\n",
    "from canns.models.basic import CANN1D, CANN2D\n",
    "from canns.task.tracking import SmoothTracking1D\n",
    "from canns.analyzer.visualize import energy_landscape_1d_animation\n",
    "\n",
    "# Set up the environment\n",
    "brainstate.environ.set(dt=0.05)  # Smaller time step for better accuracy\n",
    "print(\"Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple CANN to examine its properties\n",
    "cann = CANN1D(num=128)\n",
    "cann.init_state()\n",
    "\n",
    "print(f\"Network properties:\")\n",
    "print(f\"- Number of neurons: {cann.num}\")\n",
    "print(f\"- Feature space: [{cann.x.min():.2f}, {cann.x.max():.2f}]\")\n",
    "print(f\"- Connection matrix shape: {cann.conn_mat.shape}\")\n",
    "print(f\"- Time constant Ï„: {getattr(cann, 'tau', 'Not directly accessible')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Dynamics\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "The firing rate is typically related to the membrane potential through an activation function:\n",
    "\n",
    "$$r_i = f(u_i) = \\max(0, u_i)^n$$\n",
    "\n",
    "where $n$ controls the nonlinearity (often $n=2$ for quadratic nonlinearity).\n",
    "\n",
    "Let's visualize different activation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activation functions\n",
    "u_range = np.linspace(-2, 3, 1000)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Linear threshold (ReLU)\n",
    "relu = np.maximum(0, u_range)\n",
    "axes[0].plot(u_range, relu, 'b-', linewidth=2)\n",
    "axes[0].set_title('Linear Threshold (n=1)')\n",
    "axes[0].set_xlabel('Membrane Potential u')\n",
    "axes[0].set_ylabel('Firing Rate r')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Quadratic\n",
    "quadratic = np.maximum(0, u_range)**2\n",
    "axes[1].plot(u_range, quadratic, 'r-', linewidth=2)\n",
    "axes[1].set_title('Quadratic (n=2)')\n",
    "axes[1].set_xlabel('Membrane Potential u')\n",
    "axes[1].set_ylabel('Firing Rate r')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Cubic\n",
    "cubic = np.maximum(0, u_range)**3\n",
    "axes[2].plot(u_range, cubic, 'g-', linewidth=2)\n",
    "axes[2].set_title('Cubic (n=3)')\n",
    "axes[2].set_xlabel('Membrane Potential u')\n",
    "axes[2].set_ylabel('Firing Rate r')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Higher nonlinearity (larger n) leads to sharper, more localized activity patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity Patterns\n",
    "\n",
    "### Mexican Hat Connectivity\n",
    "\n",
    "CANNs typically use \"Mexican hat\" connectivity patterns with:\n",
    "- Short-range excitation\n",
    "- Long-range inhibition\n",
    "\n",
    "The connection weight between neurons at positions $x_i$ and $x_j$ is:\n",
    "\n",
    "$$W(x_i, x_j) = J_{ex} \\exp\\left(-\\frac{|x_i - x_j|^2}{2\\sigma_{ex}^2}\\right) - J_{in} \\exp\\left(-\\frac{|x_i - x_j|^2}{2\\sigma_{in}^2}\\right)$$\n",
    "\n",
    "Where $J_{ex}, J_{in}$ are excitatory and inhibitory strengths, and $\\sigma_{ex}, \\sigma_{in}$ are their respective ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the connectivity pattern\n",
    "center_neuron = cann.num // 2\n",
    "connectivity = cann.conn_mat[center_neuron, :]\n",
    "positions = cann.x\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot connectivity profile\n",
    "ax1.plot(positions, connectivity, 'b-', linewidth=2)\n",
    "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "ax1.set_title('Mexican Hat Connectivity Pattern')\n",
    "ax1.set_xlabel('Position Difference')\n",
    "ax1.set_ylabel('Connection Strength')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Highlight excitatory and inhibitory regions\n",
    "excitatory_mask = connectivity > 0\n",
    "inhibitory_mask = connectivity < 0\n",
    "ax1.fill_between(positions[excitatory_mask], connectivity[excitatory_mask], \n",
    "                alpha=0.3, color='red', label='Excitatory')\n",
    "ax1.fill_between(positions[inhibitory_mask], connectivity[inhibitory_mask], \n",
    "                alpha=0.3, color='blue', label='Inhibitory')\n",
    "ax1.legend()\n",
    "\n",
    "# Show full connectivity matrix (subsampled for visualization)\n",
    "step = max(1, cann.num // 64)  # Subsample for better visualization\n",
    "conn_subset = cann.conn_mat[::step, ::step]\n",
    "im = ax2.imshow(conn_subset, cmap='RdBu', origin='lower')\n",
    "ax2.set_title('Connectivity Matrix (subsampled)')\n",
    "ax2.set_xlabel('Neuron Index')\n",
    "ax2.set_ylabel('Neuron Index')\n",
    "plt.colorbar(im, ax=ax2, label='Connection Strength')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Connectivity statistics:\")\n",
    "print(f\"- Max excitation: {connectivity.max():.4f}\")\n",
    "print(f\"- Max inhibition: {connectivity.min():.4f}\")\n",
    "print(f\"- Excitatory range: ~{np.sum(connectivity > 0.01 * connectivity.max())} neurons\")\n",
    "print(f\"- Inhibitory range: ~{np.sum(connectivity < 0.01 * connectivity.min())} neurons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attractor Dynamics\n",
    "\n",
    "### Continuous Attractors\n",
    "\n",
    "The key property of CANNs is the existence of continuous attractors - stable states that form a continuous manifold in the network's state space. These attractors enable:\n",
    "\n",
    "1. **Memory without discrete states**: The network can maintain any position along the continuous attractor\n",
    "2. **Integration of inputs**: Smooth movement between attractor states\n",
    "3. **Robust representation**: Small perturbations are corrected by attractor dynamics\n",
    "\n",
    "Let's demonstrate this with a tracking experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tracking task to demonstrate attractor dynamics\n",
    "task = SmoothTracking1D(\n",
    "    cann_instance=cann,\n",
    "    Iext=(-1.5, 0., 1.5, 0.),  # Move through different positions\n",
    "    duration=(15., 15., 15., 15.),  # Longer durations to see settling\n",
    "    time_step=brainstate.environ.get_dt()\n",
    ")\n",
    "task.get_data()\n",
    "\n",
    "print(f\"Created tracking task with {len(task.data)} time steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation to observe attractor dynamics\n",
    "def run_step(t, inputs):\n",
    "    cann(inputs)\n",
    "    return cann.u.value, cann.inp.value\n",
    "\n",
    "print(\"Running attractor dynamics simulation...\")\n",
    "us, inps = brainstate.compile.for_loop(\n",
    "    run_step,\n",
    "    task.run_steps,\n",
    "    task.data,\n",
    "    pbar=brainstate.compile.ProgressBar(10)\n",
    ")\n",
    "print(\"Simulation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attractor properties\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# 1. Activity evolution over time\n",
    "im1 = axes[0,0].imshow(us.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "axes[0,0].set_title('Network Activity Over Time')\n",
    "axes[0,0].set_xlabel('Time Steps')\n",
    "axes[0,0].set_ylabel('Neuron Index')\n",
    "plt.colorbar(im1, ax=axes[0,0], label='Activity')\n",
    "\n",
    "# 2. Center of mass tracking\n",
    "def center_of_mass(activity):\n",
    "    return np.sum(activity * cann.x) / np.sum(activity)\n",
    "\n",
    "com_network = np.array([center_of_mass(u) for u in us])\n",
    "com_input = np.array([center_of_mass(inp) for inp in inps])\n",
    "\n",
    "time_axis = np.arange(len(us)) * brainstate.environ.get_dt()\n",
    "axes[0,1].plot(time_axis, com_network, 'b-', linewidth=2, label='Network CoM')\n",
    "axes[0,1].plot(time_axis, com_input, 'r--', alpha=0.7, label='Input CoM')\n",
    "axes[0,1].set_title('Center of Mass Tracking')\n",
    "axes[0,1].set_xlabel('Time')\n",
    "axes[0,1].set_ylabel('Position')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# 3. Activity width over time (measure of bump sharpness)\n",
    "def activity_width(activity, threshold=0.1):\n",
    "    max_act = activity.max()\n",
    "    if max_act > 0:\n",
    "        above_threshold = activity > threshold * max_act\n",
    "        return np.sum(above_threshold) * (cann.x[1] - cann.x[0])\n",
    "    return 0\n",
    "\n",
    "widths = np.array([activity_width(u) for u in us])\n",
    "axes[1,0].plot(time_axis, widths, 'g-', linewidth=2)\n",
    "axes[1,0].set_title('Activity Bump Width')\n",
    "axes[1,0].set_xlabel('Time')\n",
    "axes[1,0].set_ylabel('Width')\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# 4. Phase portrait (simplified - position vs velocity)\n",
    "com_velocity = np.gradient(com_network) / brainstate.environ.get_dt()\n",
    "axes[1,1].plot(com_network[:-1], com_velocity[:-1], 'purple', alpha=0.7)\n",
    "axes[1,1].scatter(com_network[0], com_velocity[0], color='green', s=50, label='Start')\n",
    "axes[1,1].scatter(com_network[-1], com_velocity[-1], color='red', s=50, label='End')\n",
    "axes[1,1].set_title('Phase Portrait (Position vs Velocity)')\n",
    "axes[1,1].set_xlabel('Position')\n",
    "axes[1,1].set_ylabel('Velocity')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Attractor analysis:\")\n",
    "print(f\"- Final tracking error: {abs(com_network[-1] - com_input[-1]):.4f}\")\n",
    "print(f\"- Average bump width: {widths.mean():.4f} Â± {widths.std():.4f}\")\n",
    "print(f\"- Position range covered: [{com_network.min():.2f}, {com_network.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Coding\n",
    "\n",
    "### Distributed Representation\n",
    "\n",
    "CANNs use population coding where:\n",
    "- Information is encoded by the activity pattern across many neurons\n",
    "- Each neuron has a preferred location (tuning curve)\n",
    "- The population response represents the current state\n",
    "\n",
    "The decoded position can be computed as:\n",
    "$$\\hat{x} = \\frac{\\sum_i r_i x_i}{\\sum_i r_i}$$\n",
    "\n",
    "This is the center of mass of the activity distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze population coding properties\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# 1. Individual neuron tuning curves\n",
    "# Sample a few neurons across the network\n",
    "sample_neurons = [cann.num//4, cann.num//2, 3*cann.num//4]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "for i, (neuron_idx, color) in enumerate(zip(sample_neurons, colors)):\n",
    "    # Get activity of this neuron across all time steps when input was present\n",
    "    neuron_activity = us[:, neuron_idx]\n",
    "    axes[0,0].plot(time_axis, neuron_activity, color=color, \n",
    "                   label=f'Neuron {neuron_idx} (x={cann.x[neuron_idx]:.2f})')\n",
    "\n",
    "axes[0,0].set_title('Individual Neuron Responses')\n",
    "axes[0,0].set_xlabel('Time')\n",
    "axes[0,0].set_ylabel('Activity')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# 2. Population vector length (total activity)\n",
    "total_activity = np.sum(us, axis=1)\n",
    "axes[0,1].plot(time_axis, total_activity, 'k-', linewidth=2)\n",
    "axes[0,1].set_title('Total Population Activity')\n",
    "axes[0,1].set_xlabel('Time')\n",
    "axes[0,1].set_ylabel('Total Activity')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# 3. Decoding accuracy over time\n",
    "decoding_error = np.abs(com_network - com_input)\n",
    "axes[1,0].plot(time_axis, decoding_error, 'orange', linewidth=2)\n",
    "axes[1,0].set_title('Population Decoding Error')\n",
    "axes[1,0].set_xlabel('Time')\n",
    "axes[1,0].set_ylabel('|Decoded - True| Position')\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# 4. Activity distribution at different time points\n",
    "time_samples = [len(us)//8, len(us)//4, len(us)//2, 3*len(us)//4]\n",
    "for i, t_idx in enumerate(time_samples):\n",
    "    axes[1,1].plot(cann.x, us[t_idx], alpha=0.7, \n",
    "                   label=f't={time_axis[t_idx]:.1f}')\n",
    "\n",
    "axes[1,1].set_title('Population Activity Snapshots')\n",
    "axes[1,1].set_xlabel('Position')\n",
    "axes[1,1].set_ylabel('Activity')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Population coding analysis:\")\n",
    "print(f\"- Mean decoding error: {decoding_error.mean():.4f}\")\n",
    "print(f\"- Max decoding error: {decoding_error.max():.4f}\")\n",
    "print(f\"- Activity range: [{total_activity.min():.2f}, {total_activity.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow Feature Analysis (SFA)\n",
    "\n",
    "### Temporal Dynamics\n",
    "\n",
    "SFA models incorporate slower dynamics to handle temporal integration:\n",
    "\n",
    "$$\\tau_s \\frac{dv_i}{dt} = -v_i + u_i$$\n",
    "\n",
    "where $v_i$ represents the slow variable and $\\tau_s >> \\tau$ is the slow time constant.\n",
    "\n",
    "This creates a multi-timescale system useful for path integration and working memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare regular CANN with SFA model\n",
    "from canns.models.basic import CANN1D_SFA\n",
    "\n",
    "# Create SFA model\n",
    "cann_sfa = CANN1D_SFA(num=128)\n",
    "cann_sfa.init_state()\n",
    "\n",
    "print(f\"Created SFA model with {cann_sfa.num} neurons\")\n",
    "print(f\"SFA model has slow dynamics for temporal integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task with brief inputs to see memory effects\n",
    "brief_task = SmoothTracking1D(\n",
    "    cann_instance=cann_sfa,\n",
    "    Iext=(1.0, 0.0, 0.0, -1.0),  # Brief inputs with gaps\n",
    "    duration=(3., 10., 10., 3.),  # Short stimulus, long gap\n",
    "    time_step=brainstate.environ.get_dt()\n",
    ")\n",
    "brief_task.get_data()\n",
    "\n",
    "# Run SFA simulation\n",
    "def run_sfa_step(t, inputs):\n",
    "    cann_sfa(inputs)\n",
    "    return cann_sfa.u.value, cann_sfa.inp.value  # Note: SFA might have different variables\n",
    "\n",
    "print(\"Running SFA simulation...\")\n",
    "us_sfa, inps_sfa = brainstate.compile.for_loop(\n",
    "    run_sfa_step,\n",
    "    brief_task.run_steps,\n",
    "    brief_task.data,\n",
    "    pbar=brainstate.compile.ProgressBar(5)\n",
    ")\n",
    "print(\"SFA simulation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SFA effects\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "time_axis_sfa = np.arange(len(us_sfa)) * brainstate.environ.get_dt()\n",
    "\n",
    "# Activity over time\n",
    "im1 = axes[0].imshow(us_sfa.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "axes[0].set_title('SFA Model: Activity Over Time')\n",
    "axes[0].set_xlabel('Time Steps')\n",
    "axes[0].set_ylabel('Neuron Index')\n",
    "plt.colorbar(im1, ax=axes[0], label='Activity')\n",
    "\n",
    "# Center of mass comparison\n",
    "com_sfa = np.array([center_of_mass(u) for u in us_sfa])\n",
    "com_input_sfa = np.array([center_of_mass(inp) for inp in inps_sfa])\n",
    "\n",
    "axes[1].plot(time_axis_sfa, com_sfa, 'b-', linewidth=2, label='SFA Network CoM')\n",
    "axes[1].plot(time_axis_sfa, com_input_sfa, 'r--', alpha=0.7, label='Input CoM')\n",
    "axes[1].set_title('SFA Model: Center of Mass Tracking (with gaps)')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Position')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Highlight input periods\n",
    "input_periods = [(0, 3), (26, 29)]  # Approximate input periods\n",
    "for start_t, end_t in input_periods:\n",
    "    axes[1].axvspan(start_t, end_t, alpha=0.2, color='yellow', label='Input present' if start_t == 0 else '')\n",
    "if len(input_periods) > 0:\n",
    "    axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"SFA effects:\")\n",
    "print(f\"- Network maintains activity during input gaps\")\n",
    "print(f\"- Slower dynamics provide temporal integration\")\n",
    "print(f\"- Useful for path integration and working memory tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Networks\n",
    "\n",
    "### Multi-Layer Processing\n",
    "\n",
    "Hierarchical networks combine multiple CANNs to create complex processing pipelines:\n",
    "\n",
    "- **Lower layers**: Process detailed, local information\n",
    "- **Higher layers**: Integrate information over larger scales\n",
    "- **Cross-layer connections**: Enable top-down and bottom-up processing\n",
    "\n",
    "This architecture is particularly useful for:\n",
    "- Multi-scale spatial representation\n",
    "- Hierarchical path integration\n",
    "- Complex decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple hierarchical network\n",
    "from canns.models.basic import HierarchicalNetwork\n",
    "\n",
    "# Create hierarchical network (if available)\n",
    "try:\n",
    "    hierarchical = HierarchicalNetwork(\n",
    "        layers=[64, 32, 16],  # Three layers with decreasing resolution\n",
    "        # Add other parameters as needed\n",
    "    )\n",
    "    hierarchical.init_state()\n",
    "    \n",
    "    print(f\"Created hierarchical network with layers: {[64, 32, 16]}\")\n",
    "    print(f\"Total parameters: ~{sum([l**2 for l in [64, 32, 16]])} connections\")\n",
    "    \n",
    "    # Demonstrate multi-scale representation\n",
    "    # (Implementation would depend on the actual HierarchicalNetwork class)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Hierarchical network demo not available: {e}\")\n",
    "    print(\"This would demonstrate multi-layer processing and cross-scale interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Implications\n",
    "\n",
    "### Design Considerations\n",
    "\n",
    "When working with CANNs, consider these key factors:\n",
    "\n",
    "1. **Network Size**: \n",
    "   - More neurons â†’ Better resolution but higher computational cost\n",
    "   - Typical range: 64-512 neurons for 1D, 32x32 to 64x64 for 2D\n",
    "\n",
    "2. **Connectivity Parameters**:\n",
    "   - Excitation/inhibition balance affects stability\n",
    "   - Connection width determines spatial resolution\n",
    "\n",
    "3. **Time Constants**:\n",
    "   - Fast dynamics for rapid tracking\n",
    "   - Slow dynamics for memory and integration\n",
    "\n",
    "4. **Input Characteristics**:\n",
    "   - Input strength affects tracking speed\n",
    "   - Input width affects final bump width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate parameter effects\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# 1. Network size effects\n",
    "sizes = [32, 64, 128, 256]\n",
    "resolutions = [(cann_x := CANN1D(num=size).x)[1] - cann_x[0] for size in sizes]\n",
    "axes[0,0].plot(sizes, resolutions, 'bo-')\n",
    "axes[0,0].set_title('Spatial Resolution vs Network Size')\n",
    "axes[0,0].set_xlabel('Number of Neurons')\n",
    "axes[0,0].set_ylabel('Spatial Resolution')\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# 2. Computational cost\n",
    "connections = [size**2 for size in sizes]  # Approximate\n",
    "axes[0,1].loglog(sizes, connections, 'ro-')\n",
    "axes[0,1].set_title('Computational Cost vs Network Size')\n",
    "axes[0,1].set_xlabel('Number of Neurons')\n",
    "axes[0,1].set_ylabel('Number of Connections')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# 3. Time constant effects (conceptual)\n",
    "time_constants = np.logspace(-1, 1, 50)\n",
    "tracking_speed = 1.0 / time_constants  # Inverse relationship\n",
    "memory_duration = time_constants * 2  # Proportional relationship\n",
    "\n",
    "axes[1,0].semilogx(time_constants, tracking_speed, 'g-', label='Tracking Speed')\n",
    "ax_twin = axes[1,0].twinx()\n",
    "ax_twin.semilogx(time_constants, memory_duration, 'purple', label='Memory Duration')\n",
    "axes[1,0].set_xlabel('Time Constant Ï„')\n",
    "axes[1,0].set_ylabel('Tracking Speed', color='g')\n",
    "ax_twin.set_ylabel('Memory Duration', color='purple')\n",
    "axes[1,0].set_title('Trade-off: Speed vs Memory')\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# 4. Input strength effects\n",
    "input_strengths = np.linspace(0.1, 2.0, 20)\n",
    "response_strengths = np.tanh(input_strengths)  # Saturating response\n",
    "tracking_errors = 1.0 / (1 + input_strengths**2)  # Decreasing error\n",
    "\n",
    "axes[1,1].plot(input_strengths, response_strengths, 'b-', label='Response Strength')\n",
    "ax_twin2 = axes[1,1].twinx()\n",
    "ax_twin2.plot(input_strengths, tracking_errors, 'r-', label='Tracking Error')\n",
    "axes[1,1].set_xlabel('Input Strength')\n",
    "axes[1,1].set_ylabel('Response Strength', color='b')\n",
    "ax_twin2.set_ylabel('Tracking Error', color='r')\n",
    "axes[1,1].set_title('Input Strength Effects')\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDesign Guidelines:\")\n",
    "print(\"1. Choose network size based on required spatial resolution\")\n",
    "print(\"2. Balance computational cost with accuracy needs\")\n",
    "print(\"3. Adjust time constants for speed vs stability trade-off\")\n",
    "print(\"4. Use appropriate input strengths to avoid saturation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered the core mathematical and conceptual foundations of CANNs:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "1. **Mathematical Foundation**: Differential equations governing network dynamics\n",
    "2. **Network Dynamics**: Activation functions and temporal evolution\n",
    "3. **Connectivity Patterns**: Mexican hat connectivity enabling attractor formation\n",
    "4. **Attractor Dynamics**: Continuous manifolds of stable states\n",
    "5. **Population Coding**: Distributed representation and decoding\n",
    "6. **Slow Feature Analysis**: Multi-timescale dynamics for integration\n",
    "7. **Hierarchical Networks**: Multi-layer processing architectures\n",
    "8. **Practical Implications**: Design considerations and trade-offs\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "Now that you understand the core concepts, you can:\n",
    "\n",
    "- Explore detailed **1D CANN implementations** in the next notebook\n",
    "- Learn about **2D spatial representations** for complex environments\n",
    "- Implement **custom tasks** tailored to your research needs\n",
    "- Apply **advanced visualization techniques** for analysis\n",
    "- Optimize **performance** for large-scale simulations\n",
    "\n",
    "### Resources for Further Learning:\n",
    "\n",
    "- **Mathematical Details**: See the original CANN papers and reviews\n",
    "- **Implementation Examples**: Check the `examples/` directory\n",
    "- **API Documentation**: Complete reference for all classes and functions\n",
    "- **Community Support**: Join discussions and get help from other users\n",
    "\n",
    "The solid foundation you've built here will serve you well as you dive deeper into specific applications and advanced techniques! ðŸ§ ðŸ”¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}