# Tier 3: Core Concepts - Planning Questions

**Status**: ğŸ”´ Awaiting your answers
**Target Audience**: Engineers/Developers, Graduate students, Cross-domain collaborators
**Estimated Reading Time per Topic**: 15-20 minutes
**Writing Style**: Conceptual, explanatory, linking theory to practice

---

## ğŸ“‹ Section Overview

The "Core Concepts" tier provides **in-depth explanations** of library design and components. These are NOT how-to guides (that's Tier 2), but rather **conceptual foundations** that help users understand:
- Why the library is designed this way
- How different components work together
- When to use which approach
- The theoretical background behind implementations

**Key difference from other tiers**:
- Tier 1 (Why CANNs): Motivation and value proposition
- Tier 2 (Basic Intro): Practical how-to guides
- **Tier 3 (Core Concepts)**: Deep conceptual understanding
- Tier 4 (Full Details): Complete API reference with examples

---

## ğŸ¯ The 5 Core Concept Topics

Based on your outline (`docs-arch.md`), Tier 3 covers:

1. **Overview (Design Philosophy)** - Architecture, module organization, design principles
2. **Model Collections** - Basic CANNs, Hybrid models, Brain-Inspired models
3. **Task Generators** - Tracking, navigation, population coding paradigms
4. **Analysis Methods** - Model Analyzer, Data Analyzer, RNN Dynamics Analysis
5. **Brain-Inspired Training** - Learning rules, trainer framework

---

## Topic 1: Overview & Design Philosophy

### Context
This reorganizes the existing `00_design_philosophy.rst` (661 lines) into a more focused overview that ties everything together.

### Q1.1: What are the core design principles of the library?
The existing design philosophy explains modules but doesn't highlight **key principles**. What principles should we emphasize?

Examples:
- Separation of concerns (models â‰  tasks â‰  analyzers)
- BrainState integration for dynamics
- Extensibility through base classes
- JAX-first for performance
- Other principles?

**Your Answer:**
```
ä¸»è¦è¯´Separation of concernså’ŒExtensibility through base classeså§
```

---

### Q1.2: How should we explain the module hierarchy?
Current doc has a flat list of modules. Should we show:
- **Dependency graph** (which modules depend on others)?
- **Workflow diagram** (typical usage flow)?
- **Layered architecture** (low-level to high-level)?

**Your Answer:**
```
workflow diagramå¯èƒ½æ¯”è¾ƒå¥½äº›
```

---

### Q1.3: What should be preserved from current design_philosophy.rst?
The current document covers:
- Module overview (models, task, analyzer, trainer, pipeline)
- Usage examples
- Extension guides

**Your Answer:**
```
å°½é‡éƒ½ä¿ç•™å§ï¼Œç„¶åçœ‹çœ‹æœ‰ä»€ä¹ˆimproveçš„
```

---

### Q1.4: How much technical depth for Overview?
Should Overview include:
- Code examples showing module interaction?
- Technical implementation details?
- Or just high-level concepts with links to other topics?

**Your Answer:**
```
just high-level concepts with links to other topics
```

---

## Topic 2: Model Collections

### Context
Explains the three model categories: Basic CANN, Hybrid (TODO), Brain-Inspired

### Q2.1: What makes each model category distinct?
Help readers understand when to use which:
- **Basic CANN Models**: When to use? What problems do they solve?
- **Hybrid Models**: What's the concept? (even if TODO, explain the vision)
- **Brain-Inspired Models**: How do they differ from Basic CANNs?

**Your Answer:**
```
æ¨¡å‹æ¨¡å—å®ç°ä¸åŒç»´åº¦çš„CANNåŸºç¡€æ¨¡å‹åŠå…¶å˜ä½“ï¼Œè„‘å¯å‘æ¨¡å‹ä»¥åŠCANNæ··åˆæ¨¡å‹ã€‚è¯¥æ¨¡å—æ˜¯æœ¬åº“çš„åŸºç¡€ï¼Œå¯ä»¥ä¸å…¶ä»–çš„æ¨¡å—æ¥è¿›è¡Œäº¤äº’æ¥å®ç°å„ç§åœºæ™¯çš„åº”ç”¨ã€‚
è¿™é‡Œæ ¹æ®ä¸åŒçš„æ¨¡å‹ç±»å‹è¿›è¡Œåˆ†ç±»ï¼š
Basic Models (canns.models.basic) åŸºç¡€çš„CANNsæ¨¡å‹åŠå…¶å„ä¸ªå˜ä½“ã€‚
Brain-Inspired Models (canns.models.brain_inspired) ç±»è„‘æ¨¡å‹ã€‚
Hybrid Models (canns.models.hybrid) CANNä¸ANNæˆ–å…¶ä»–çš„æ··åˆæ¨¡å‹ã€‚
åœ¨è¿™é‡Œä¸»è¦ä¾èµ–Brain simulation ecosystemä¸­çš„brainstateæ¥å®ç°å„ä¸ªæ¨¡å‹ã€‚brainstateÂ æ˜¯ Brain Simulation Ecosystem ä¸­é¢å‘åŠ¨åŠ›ç³»ç»Ÿçš„æ ¸å¿ƒæ¡†æ¶ï¼Œåº•å±‚åŸºäº JAX/BrainUnitã€‚å®ƒæä¾›Â brainstate.nn.DynamicsÂ æŠ½è±¡ã€State/HiddenState/ParamStateÂ çŠ¶æ€å®¹å™¨ä»¥åŠÂ brainstate.environÂ ç»Ÿä¸€çš„æ—¶é—´æ­¥é•¿ç®¡ç†ï¼Œä¸Â brainstate.compile.for_loopã€brainstate.randomÂ ç­‰å·¥å…·ä¸€èµ·ï¼Œè®©æˆ‘ä»¬å¯ä»¥å†™å‡ºæ—¢å¯ JIT ç¼–è¯‘åˆæ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„ç¥ç»ç½‘ç»œåŠ¨åŠ›å­¦ã€‚å€ŸåŠ©è¿™äº›æ¥å£ï¼ŒCANN æ¨¡å‹åªéœ€æè¿°å˜é‡ä¸æ›´æ–°æ–¹ç¨‹ï¼Œæ—¶é—´æ¨è¿›ã€å¹¶è¡ŒåŒ–å’Œéšæœºæ•°ç®¡ç†éƒ½ç”±Â brainstateÂ è´Ÿè´£ï¼Œä»è€Œæ˜¾è‘—é™ä½å®ç°æˆæœ¬ã€‚
```

---

### Q2.2: Should we explain the BaseCANN abstraction?
The library has `BaseCANN` as parent class for CANN1D/2D.
- Explain the abstract methods (`cell_coords`, `f_r`, `f_u`, `f_r_given_u`)?
- Show how inheritance works?
- Or keep it high-level?

**Your Answer:**
```
æ¯ä¸ªæ¨¡å‹éƒ½ç»§æ‰¿è‡ªcanns.models.basic.BasicModelæˆ–canns.models.basic.BasicModelGroupç±»ï¼Œå¹¶å®ç°äº†ä»¥ä¸‹ä¸»è¦æ–¹æ³•ï¼š
åœ¨åŸºç¡€æ¨¡å‹ä¸­éœ€è¦å®Œæˆçš„ä¸»è¦å·¥ä½œï¼š
ç»§æ‰¿Â canns.models.basic.BasicModelÂ æˆ–Â BasicModelGroupï¼Œåœ¨Â __init__Â ä¸­è°ƒç”¨çˆ¶ç±»æ„é€ ï¼ˆä¾‹å¦‚Â super().__init__(math.prod(shape),Â **kwargs)ï¼‰å¹¶ä¿å­˜å¥½Â shapeã€varshapeÂ ç­‰ç»´åº¦ä¿¡æ¯ï¼›
å®ç°Â make_conn()Â ç”Ÿæˆè¿æ¥çŸ©é˜µï¼Œå¹¶åœ¨æ„é€ å‡½æ•°é‡Œèµ‹å€¼ç»™Â self.conn_matï¼ˆå¯å‚è€ƒÂ src/canns/models/basic/cann.pyÂ ä¸­çš„é«˜æ–¯æ ¸å®ç°ï¼‰ï¼›
å®ç°Â get_stimulus_by_pos(pos)ï¼Œæ ¹æ®ç‰¹å¾ç©ºé—´çš„ä½ç½®è¿”å›å¤–éƒ¨åˆºæ¿€ï¼Œä¾›ä»»åŠ¡æ¨¡å—è°ƒç”¨ï¼›
åœ¨Â init_state()Â æ³¨å†ŒÂ brainstate.HiddenState/Stateï¼ˆå¸¸è§çš„æœ‰Â self.uã€self.rã€self.inpï¼‰ï¼Œç¡®ä¿æ›´æ–°å‡½æ•°èƒ½å¤Ÿç›´æ¥è¯»å†™ï¼›
åœ¨Â update(inputs)Â ä¸­å†™å‡ºå•æ­¥åŠ¨åŠ›å­¦ï¼Œè®°å¾—ä¹˜ä»¥Â brainstate.environ.get_dt()Â ç»´æŒæ•°å€¼ç¨³å®šï¼›
éœ€è¦æš´éœ²è¯Šæ–­é‡æˆ–è½´ä¿¡æ¯æ—¶ï¼Œé€šè¿‡å±æ€§/æ–¹æ³•è¿”å›ï¼ˆå¦‚Â self.xã€self.rhoï¼‰ï¼Œä¾›ä»»åŠ¡ã€åˆ†æå™¨å’Œæµæ°´çº¿é‡ç”¨ã€‚
å¯¹äºè„‘å¯å‘æ¨¡å‹
æ¯ä¸ªæ¨¡å‹éƒ½ç»§æ‰¿è‡ªcanns.models.brain_inspired.BrainInspiredModelæˆ–canns.models.brain_inspired.BrainInspiredModelGroupç±»ï¼Œå¹¶å®ç°äº†
è‹¥è¦æ‰©å±•è„‘å¯å‘æ¨¡å‹ï¼ˆç»§æ‰¿Â BrainInspiredModelÂ æˆ–Â BrainInspiredModelGroupï¼‰ï¼Œè¯·ç¡®ä¿ï¼š
åœ¨Â init_state()Â ä¸­è‡³å°‘æ³¨å†ŒçŠ¶æ€å‘é‡ï¼ˆé»˜è®¤Â self.sï¼‰å’Œè¿æ¥æƒé‡Â self.Wï¼Œå…¶ä¸­Â self.WÂ å»ºè®®ä½¿ç”¨Â brainstate.ParamStateÂ ä»¥ä¾¿ Hebbian å­¦ä¹ ç›´æ¥å†™å…¥ï¼›
å¦‚æœæƒé‡å±æ€§åç§°ä¸æ˜¯Â Wï¼Œé‡å†™Â weight_attrÂ ä»¥ä¾¿Â HebbianTrainerÂ èƒ½æ‰¾åˆ°ï¼›
å®ç°Â update(...)Â ä¸Â energyÂ å±æ€§ï¼Œç¡®ä¿è®­ç»ƒå™¨å¯ä»¥è¿è¡Œé€šç”¨é¢„æµ‹å¾ªç¯å¹¶åˆ¤å®šæ”¶æ•›ï¼›
éœ€è¦å®šåˆ¶ Hebbian è§„åˆ™æ—¶å®ç°Â apply_hebbian_learning(patterns)ï¼Œå¦åˆ™å¯ä»¥å®Œå…¨ä¾èµ–è®­ç»ƒå™¨çš„é€šç”¨å®ç°ï¼›
è‹¥æ¨¡å‹æ”¯æŒåŠ¨æ€å°ºå¯¸è°ƒæ•´ï¼Œå¯é‡å†™Â resize(num_neurons,Â preserve_submatrix=True)ï¼Œå‚è€ƒÂ src/canns/models/brain_inspired/hopfield.pyÂ ä¸­çš„åšæ³•ã€‚
```

---

### Q2.3: How to explain model variants (e.g., CANN1D vs CANN1D_SFA)?
- Focus on **conceptual differences** (SFA adds adaptation)?
- Show **when to choose** each variant?
- Include **parameter comparison**?

**Your Answer:**
```
å°±æ˜¯å¢åŠ æ–°çš„ç‰¹æ€§
```

---

### Q2.4: Hierarchical models (grid cells, place cells)?
These are special:
- Part of Basic Models but more complex
- Should they have dedicated explanation?
- How to explain the hierarchy concept?

**Your Answer:**
```
å…¶ä¹Ÿæ˜¯ç›¸å½“äºCANNçš„å˜ä½“ï¼Œæ€æƒ³ä¸æ€è·¯ä¸åŸºç¡€CANNä¸€è‡´ï¼Œä¸è¿‡å®ç°æœ‰äº›åŒºåˆ«
```

---

## Topic 3: Task Generators

### Context
Explain the task generation philosophy and available paradigms

### Q3.1: What's the key concept users need to understand about tasks?
Tasks are more than just "data generators". What's the deeper concept?
- Experimental paradigm abstraction?
- Model-task coupling philosophy?
- Reproducibility and standardization?

**Your Answer:**
```
ä»»åŠ¡æ¨¡å—ä¸»è¦ç”¨äºç”Ÿæˆã€ä¿å­˜ã€è¯»å–ã€å¯¼å…¥å’Œå¯è§†åŒ–å„ç§CANNä»»åŠ¡ã€‚è¯¥æ¨¡å—æä¾›äº†å¤šç§é¢„å®šä¹‰çš„ä»»åŠ¡ç±»å‹ï¼Œå¹¶å…è®¸ç”¨æˆ·è‡ªå®šä¹‰ä»»åŠ¡ä»¥æ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚
```

---

### Q3.2: How should we organize task types?
Current categories:
- Tracking (smooth, oscillatory)
- Closed-loop navigation
- Open-loop navigation
- Population coding

Should we organize by:
- **Cognitive function** (spatial navigation, memory encoding)?
- **Input pattern** (static, dynamic, feedback-driven)?
- **Use case** (research, benchmarking, teaching)?

**Your Answer:**
```
è¿™é‡Œæš‚æ—¶å°±ä¸¤ç±»ï¼ŒTrackingä»»åŠ¡å’ŒNavigationä»»åŠ¡ï¼Œç„¶åå…¶ä¸­trackingåˆåˆ†ä¸º
- population coding
- template matching
- smooth tracking
navigationçš„è¯åˆ†æˆ
- closed loop navigation
- open loop navigation
```

---

### Q3.3: How much detail on task-model coupling?
Some tasks need `cann_instance` (like SmoothTracking1D).
- Explain **why** this coupling exists (get_stimulus_by_pos)?
- Show **when** coupling is necessary vs. optional?
- Discuss trade-offs?

**Your Answer:**
```
ç›®å‰åªæœ‰tracking taskæ˜¯éœ€è¦ä¼ å…¥modelæ¥è·å–å¯¹åº”çš„stimulusçš„ï¼Œå› ä¸ºåŸºæœ¬çš„CANN modeléƒ½æ˜¯è¿™æ ·å­æ¥è¿›è¡Œè¾“å…¥çš„ï¼Œæˆ‘ä»¬æƒ³è¦åšåˆ°æ›´user-firendlyï¼Œæ‰€ä»¥æš‚æ—¶éœ€è¦couplingï¼Œå¯¹äºnavigationå°±ä¸éœ€è¦äº†ï¼Œå› ä¸ºå¯èƒ½æˆ‘ä»¬éœ€è¦æä¾›æ›´å¤šçš„dataä¿¡æ¯ï¼ˆæ¯”å¦‚é€Ÿåº¦ã€è§’åº¦ç­‰ç­‰ï¼‰ç„¶åè®©ç”¨æˆ·è‡ªè¡Œåˆ¤æ–­æ¥å»ä½¿ç”¨ã€‚
```

---

### Q3.4: Should we explain trajectory import?
The library can import external trajectories.
- Just mention it exists?
- Explain use cases (real experimental data)?
- Show conceptual workflow?

**Your Answer:**
```
å¯ä»¥ç®€å•æä¸€ä¸‹ï¼Œä¸ç”¨ç‰¹åˆ«å»è¯¦ç»†è¯´æ˜ï¼Œè¿™æ˜¯åé¢è¦åšçš„äº‹æƒ…
```

---

## Topic 4: Analysis Methods

### Context
Covers Model Analyzer, Data Analyzer, and RNN Dynamics Analysis

### Q4.1: Model Analyzer vs. Data Analyzer - key distinction?
Help users understand which to use when:
- Model Analyzer: Analyzing **simulation outputs**?
- Data Analyzer: Analyzing **experimental recordings**?
- What's the philosophical difference?

**Your Answer:**
```
æ˜¯çš„ï¼Œä¸è¿‡model analyzerä¸»è¦æ˜¯å¯¹æˆ‘ä»¬ç°åœ¨çš„ä¸€äº›CANN modelçš„è¾“å‡ºåšä¸€äº›åˆ†æå¯è§†åŒ–ï¼Œç„¶ådata analyzerä¸»è¦æ˜¯å¯¹å®éªŒæ•°æ®ï¼ˆä¸€èˆ¬å¯èƒ½æ˜¯spike trainæˆ–è€…æ˜¯firing rateï¼‰ä»¥åŠå¯ä»¥ç”Ÿæˆè¿™ä¸€ç±»çš„è™šæ‹Ÿæ•°æ®æ¥å»è¿›è¡Œåˆ†æå¯è§†åŒ–
```

---

### Q4.2: PlotConfig design philosophy?
Why did we create PlotConfig instead of just function arguments?
- Reusability?
- Type safety?
- Configuration sharing?

Should we explain this design choice?

**Your Answer:**
```
ç®€å•æä¸€ä¸‹PlotConfigå§
```

---

### Q4.3: RNN Dynamics Analysis - scope?
Your outline mentions:
- Slow and fixed points analysis

Is this:
- For analyzing CANN models as RNNs?
- For analyzing arbitrary trained RNNs?
- Both?

**Your Answer:**
```
æš‚æ—¶åªç”¨äºåˆ†æRNN model
```

---

### Q4.4: Topological Data Analysis (TDA)?
The library has TDA tools (UMAP, persistent homology).
- Explain **why** TDA for CANNs (detecting torus structure)?
- Show **when** to use it?
- Keep it high-level or include math?

**Your Answer:**
```
æ˜¯çš„ï¼Œæˆ‘ä»¬cann-libæä¾›äº†åŠ é€Ÿçš„ripseræŒç»­åŒè°ƒæ–¹æ³•ï¼Œä½†å¯¹äºé™ç»´å·¥å…·ï¼Œæˆ‘ä»¬è¿™é‡Œæ²¡æœ‰é‡æ–°å®ç°ï¼Œç”¨æˆ·å¯ä»¥è‡ªè¡Œä½¿ç”¨ï¼Œæˆ‘ä»¬å¯èƒ½åœ¨æŸäº›tdaä¸­ä¼šæœ‰è°ƒç”¨å¤–éƒ¨æ–¹æ³•ï¼Œå› ä¸ºgrid cellæ˜¯æœ‰torus structureçš„ï¼Œç„¶åå¯èƒ½æœ‰ä¸€äº›æ‹“æ‰‘ç»“æ„èƒ½å¤Ÿç”¨CANNæ¥å»æ„å»ºï¼Œæ‰€ä»¥æˆ‘ä»¬å¸Œæœ›æœ‰è¿™æ ·çš„å·¥å…·æ¥å»æ¢ç´¢æ•°æ®ä¸­æœ‰æ²¡æœ‰attractor structure
```

---

## Topic 5: Brain-Inspired Training

### Context
Learning rules (Hebbian, STDP, BCM) and the Trainer framework

### Q5.1: What's the unifying concept of brain-inspired learning?
Beyond "local vs. global", what ties these rules together?
- Biological plausibility?
- Unsupervised learning?
- Synaptic plasticity mechanisms?

**Your Answer:**
```
åº”è¯¥æ˜¯activity-dependent plasticity
```

---

### Q5.2: How much neuroscience background?
Different learning rules have neuroscience origins:
- Hebbian: "Neurons that fire together wire together"
- STDP: Spike-timing dependent plasticity
- BCM: Bienenstock-Cooper-Munro rule

Should we:
- Explain the neuroscience briefly?
- Just describe algorithmic behavior?
- Link to external neuroscience resources?

**Your Answer:**
```
åªæ˜¯å¤§æ¦‚ç®€å•è¯´ä¸‹å§ï¼Œè¿™éƒ¨åˆ†è¿˜æ˜¯ä¸»è¦æ˜¯å¦‚ä½•ç»Ÿä¸€å»ç”¨trainerè¿™ä¸ªmodule
```

---

### Q5.3: Trainer abstraction - design rationale?
Why separate `Trainer` from `Model`?
- Separation of concerns?
- Swappable learning rules?
- Unified API?

**Your Answer:**
```
è®­ç»ƒæ¨¡å—æä¾›äº†ç»Ÿä¸€çš„æ¥å£ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°ç±»è„‘æ¨¡å‹ã€‚

ç”¨æˆ·å¯ä»¥é€šè¿‡ç»§æ‰¿canns.trainer.Trainerç±»æ¥åˆ›å»ºè‡ªå®šä¹‰çš„è®­ç»ƒå™¨ã€‚éœ€è¦å®ç°ä»¥ä¸‹ä¸»è¦æ–¹æ³•ï¼š
è‹¥è¦å®ç°æ–°çš„è®­ç»ƒå™¨ï¼Œéœ€ç»§æ‰¿Â canns.trainer.TrainerÂ å¹¶ï¼š
åœ¨æ„é€ å‡½æ•°ä¸­ä¿å­˜ç›®æ ‡æ¨¡å‹åŠè¿›åº¦æ˜¾ç¤ºé…ç½®ï¼›
å®ç°Â train(self,Â train_data)ï¼Œå®šä¹‰å‚æ•°æ›´æ–°ç­–ç•¥ï¼›
å®ç°Â predict(self,Â pattern,Â *args,Â **kwargs)ï¼Œç»™å‡ºå•æ ·æœ¬æ¨ç†é€»è¾‘ï¼Œå¿…è¦æ—¶ä½¿ç”¨Â predict_batchå°è£…æ‰¹é‡æ¨ç†ï¼›
éµå¾ªé»˜è®¤çš„Â configure_progressÂ çº¦å®šï¼Œè®©ç”¨æˆ·å¯ä»¥æ‰“å¼€/å…³é—­è¿›åº¦æ¡æˆ–ç¼–è¯‘æ¨¡å¼ï¼›
å½“è®­ç»ƒå™¨éœ€è¦ä¸ç‰¹å®šæ¨¡å‹åä½œæ—¶ï¼Œçº¦å®šå¥½å…¬å…±å±æ€§åï¼ˆå¦‚æƒé‡ã€çŠ¶æ€å‘é‡ï¼‰ä»¥ä¿è¯äº’æ“ä½œæ€§ã€‚
```

---

### Q5.4: Comparison with deep learning training?
Should we explicitly contrast:
- Hebbian vs. Backpropagation?
- Local vs. Global learning?
- When to use which?

Or assume readers already understand deep learning?

**Your Answer:**
```
è¿™ä¸ªæ„Ÿè§‰ä¸ç”¨è¯´ä»€ä¹ˆï¼Œæ²¡å¿…è¦è§£é‡Šå¤ªå¤š
```

---

## Cross-Cutting Questions

### QX.1: Depth vs. Breadth balance?
Core Concepts should be:
- **Broad** survey of all components?
- **Deep** dive into fewer key topics?
- **Balanced** - moderate depth across all topics?

**Your Answer:**
```
balancedå§ï¼Œæœ€å¥½ç”¨æˆ·æ˜“æ‡‚åœ°ä»‹ç»
```

---

### QX.2: Code examples in Core Concepts?
Should these conceptual docs include:
- **No code** - pure concepts and diagrams?
- **Code snippets** - to illustrate concepts?
- **Full examples** - like Tier 2 but more annotated?

**Your Answer:**
```
è¿™é‡Œå°±ä¸è¦æä»£ç äº†ï¼Œå¯ä»¥è¯´å…·ä½“çš„moduleæˆ–è€…æ˜¯classä¸­çš„å±æ€§
```

---

### QX.3: Diagrams and visualizations?
Would diagrams help? Which types:
- **Architecture diagrams** (module relationships)?
- **Workflow diagrams** (data flow)?
- **Conceptual diagrams** (e.g., attractor landscape)?
- **UML/class diagrams**?

**Your Answer:**
```
workflowå¯ä»¥æ ¹æ®ä¸‹tier2ä¸­çš„å‡ ä¸ªhowæ¥å»å±•ç¤º
```

---

### QX.4: Cross-references to Tier 2 and Tier 4?
How should Core Concepts link to other tiers?
- Forward links to Tier 4 (Full Details)?
- Back links to Tier 2 (Basic Intro)?
- "For hands-on guide see..., for complete API see..."?

**Your Answer:**
```
æš‚æ—¶å…ˆç•™ç€markå§ï¼Œä»¥åéƒ½å®Œæˆåå†ç»Ÿä¸€åŠ 
```

---

### QX.5: Comparison with other frameworks?
Should Core Concepts compare design choices with:
- Other neural network libraries (PyTorch, TensorFlow)?
- Other neuroscience simulation tools (NEST, Brian2)?
- Or focus only on CANNs library design?

**Your Answer:**
```
æš‚æ—¶ä¸è¦æäº†
```

---

## ğŸ“ Document Length Guidelines

**Target**: Each of the 5 topics should be ~1500-2500 words
- Longer than Tier 2 (more depth)
- Shorter than Tier 4 (not exhaustive reference)
- Readable in 15-20 minutes

Is this appropriate?

**Your Answer:**
```
ä¸»è¦è®²æ ¸å¿ƒéƒ¨åˆ†ï¼Œå°½é‡ç²¾ç®€ï¼Œåº”è¯¥å’Œtier2å·®ä¸å¤šï¼Œè€Œä¸”è¿™éƒ¨åˆ†åº”è¯¥ä¸ä¼šæœ‰ä»€ä¹ˆä»£ç ï¼Œæ‰€ä»¥å¯èƒ½è¿˜æ¯”tier2çŸ­
```

---

## ğŸ“š Relationship to Existing Design Philosophy

The current `00_design_philosophy.rst` is comprehensive (661 lines). How should we handle it?

**Option 1**: Break it into all 5 Core Concept topics
- Overview gets intro + module list
- Each module gets its own topic (Models â†’ Topic 2, Tasks â†’ Topic 3, etc.)

**Option 2**: Keep it as "Overview" and create new focused docs for other topics
- Preserve current design_philosophy mostly intact
- Add 4 new topic-specific documents

**Option 3**: Hybrid approach
- Streamline overview to essentials
- Expand with new focused sections per topic
- Some content reused, some new

**Your Answer:**
```
æ„Ÿè§‰ä¸ç”¨å¤ªåŠ¨è¿™ä¸ª
```

---

## âœ… Next Steps After Answering

Once you've completed your answers:
1. Save this file
2. Let me know you're done
3. I'll generate draft documentation for all 5 Core Concept topics
4. We'll review together and iterate as needed

---

**Tips for Answering**:
- Think about what YOU needed when learning the library
- Consider different reader backgrounds (student, researcher, engineer)
- Balance between accessibility and technical depth
- Remember: This is "concepts", not "tutorials" or "API reference"
- Focus on the "why" and "when", not just the "how"
